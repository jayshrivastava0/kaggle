{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":76728,"databundleVersionId":9057646,"sourceType":"competition"},{"sourceId":6478229,"sourceType":"datasetVersion","datasetId":3742543},{"sourceId":9489899,"sourceType":"datasetVersion","datasetId":5773675},{"sourceId":9511778,"sourceType":"datasetVersion","datasetId":5789956},{"sourceId":196651220,"sourceType":"kernelVersion"},{"sourceId":198609771,"sourceType":"kernelVersion"}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n\n# A big thanks to @Backpacker for his notebook.This notebook relies heavily on his work, go see his original notebook if you like this one!\n\n# The modification of this notebook comes in the usage of autogluon for the final predictor.\n","metadata":{}},{"cell_type":"code","source":"# This may take a while\n\n!pip install -U autogluon","metadata":{"execution":{"iopub.status.busy":"2024-09-29T21:27:24.044432Z","iopub.execute_input":"2024-09-29T21:27:24.044854Z","iopub.status.idle":"2024-09-29T21:31:54.114353Z","shell.execute_reply.started":"2024-09-29T21:27:24.044811Z","shell.execute_reply":"2024-09-29T21:31:54.112316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from autogluon.tabular import TabularPredictor\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport re\ntrain = pd.read_csv('/kaggle/input/playground-series-s4e9/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s4e9/test.csv')\nOriginal = pd.read_csv('/kaggle/input/used-car-price-prediction-dataset/used_cars.csv')\nOriginal[['milage', 'price']] = Original[['milage', 'price']].map(\n    lambda x: int(''.join(re.findall(r'\\d+', x))))\nimport lightgbm as lgb\nfrom lightgbm import log_evaluation, early_stopping\nfrom catboost import CatBoostRegressor, Pool\n\nfrom xgboost import XGBRegressor\n\n\nimport random\n\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n\nfrom autogluon.tabular import TabularPredictor\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T21:31:54.118119Z","iopub.execute_input":"2024-09-29T21:31:54.118693Z","iopub.status.idle":"2024-09-29T21:31:59.334800Z","shell.execute_reply.started":"2024-09-29T21:31:54.118641Z","shell.execute_reply":"2024-09-29T21:31:59.333714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import datasets, as well as the original one (before transformation for this competition)\n","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s4e9/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s4e9/test.csv')\nOriginal = pd.read_csv('/kaggle/input/used-car-price-prediction-dataset/used_cars.csv')\nOriginal[['milage', 'price']] = Original[['milage', 'price']].map(\n    lambda x: int(''.join(re.findall(r'\\d+', x))))\n\n\ntrain.drop(columns=['id'], inplace=True)\ntest.drop(columns=['id'], inplace=True)\n\n\ntrain = pd.concat([train, Original], ignore_index=True)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T21:31:59.336319Z","iopub.execute_input":"2024-09-29T21:31:59.337099Z","iopub.status.idle":"2024-09-29T21:32:00.377132Z","shell.execute_reply.started":"2024-09-29T21:31:59.337058Z","shell.execute_reply":"2024-09-29T21:32:00.376075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Several feature engineer step taken by fellow kagglers, explanation comes for the diverse public notebook of the competition","metadata":{}},{"cell_type":"code","source":"def extract_age_features(df):\n    current_year = 2024\n\n    df['Vehicle_Age'] = current_year - df['model_year']\n    \n    df['Mileage_per_Year'] = df['milage'] / df['Vehicle_Age']\n    df['milage_with_age'] =  df.groupby('Vehicle_Age')['milage'].transform('mean')\n    \n    df['Mileage_per_Year_with_age'] =  df.groupby('Vehicle_Age')['Mileage_per_Year'].transform('mean')\n    \n    return df\n\n\ndef extract_other_features(df):\n    \n    luxury_brands =  ['Mercedes-Benz', 'BMW', 'Audi', 'Porsche', 'Land', \n                    'Lexus', 'Jaguar', 'Bentley', 'Maserati', 'Lamborghini', \n                    'Rolls-Royce', 'Ferrari', 'McLaren', 'Aston', 'Maybach']\n    df['Is_Luxury_Brand'] = df['brand'].apply(lambda x: 1 if x in luxury_brands else 0)\n    \n\n\n\n    return df\n\ntrain = extract_age_features(train)\ntest = extract_age_features(test)\n\ntrain = extract_other_features(train)\ntest = extract_other_features(test)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T21:32:00.379580Z","iopub.execute_input":"2024-09-29T21:32:00.379974Z","iopub.status.idle":"2024-09-29T21:32:00.595722Z","shell.execute_reply.started":"2024-09-29T21:32:00.379934Z","shell.execute_reply":"2024-09-29T21:32:00.594483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def update(df):\n    \n    t = 100\n    \n    cat_c = ['brand','model','fuel_type','engine','transmission','ext_col','int_col','accident','clean_title',\n             \n            ]\n    re_ = ['model','engine','transmission','ext_col','int_col']\n    \n    for col in re_:\n        df.loc[df[col].value_counts(dropna=False)[df[col]].values < t, col] = \"noise\"\n        \n    for col in cat_c:\n        df[col] = df[col].fillna('missing')\n        df[col] = df[col].astype('category')\n        \n    return df\n\ntrain  = update(train)\ntest   = update(test)\n\nX = train.drop('price', axis=1)\ny = train['price']","metadata":{"execution":{"iopub.status.busy":"2024-09-29T21:32:00.597193Z","iopub.execute_input":"2024-09-29T21:32:00.597567Z","iopub.status.idle":"2024-09-29T21:32:01.434349Z","shell.execute_reply.started":"2024-09-29T21:32:00.597529Z","shell.execute_reply":"2024-09-29T21:32:01.432968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Calculation of the MAE and difference between MSE and MAE. Thanks to @Backpacker for the idea and the code","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport lightgbm as lgb\nfrom catboost import CatBoostRegressor, Pool\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n\n\n\ncallbacks = [log_evaluation(period=300), early_stopping(stopping_rounds=200)]\n\ncat_cols = train.select_dtypes(include=['object', 'category']).columns.tolist()\n\nprint(f\"cat_cols--------{cat_cols}\")\n\n\ndef get_MAE_oof(df, target, lgb_params, cat_params=None, model_type='LGBM'):\n\n    \n    oof_predictions = np.zeros(len(df))\n    kf = KFold(n_splits=5, shuffle=True, random_state=1)\n    models = []\n    rmse_scores = []\n    \n    for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n        print(f\"Training fold {fold + 1}/{5} with {model_type}\")\n\n        X_train, X_val = df.iloc[train_idx], df.iloc[val_idx]\n        y_train, y_val = target.iloc[train_idx], target.iloc[val_idx]\n\n        if model_type == 'LGBM':\n            train_data = lgb.Dataset(X_train, label=y_train)\n            val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n            \n            model = lgb.train(\n                lgb_params,\n                train_data,\n                valid_sets=[train_data, val_data],\n                valid_names=['train', 'valid'],\n                callbacks=callbacks    \n            )\n        \n        elif model_type == 'CAT':\n            train_data = Pool(data=X_train, label=y_train , cat_features=cat_cols)\n            val_data = Pool(data=X_val, label=y_val , cat_features=cat_cols )\n            \n            model = CatBoostRegressor(**cat_params)\n            model.fit(train_data, eval_set=val_data, verbose=150, early_stopping_rounds=200)\n        \n        models.append(model)\n        \n        if model_type == 'LGBM':\n            pred = model.predict(X_val, num_iteration=model.best_iteration)\n        elif model_type == 'CAT':\n            pred = model.predict(X_val)\n        \n        rmse = np.sqrt(mean_squared_error(y_val, pred))\n        rmse_scores.append(rmse)\n\n        print(f'{model_type} Fold RMSE: {rmse}')\n        \n        oof_predictions[val_idx] = pred\n        \n    print(f'Mean RMSE: {np.mean(rmse_scores)}')\n    return oof_predictions, models\n\n\n\n\nlgb_params = {\n    'objective': 'MAE',\n    'n_estimators': 1000,\n    'random_state': 1,\n}\n\noof_predictions_lgbm, models_lgbm = get_MAE_oof(X, y, lgb_params, model_type='LGBM')\nX['LGBM_MAE'] = oof_predictions_lgbm\n\n\nLGBM_preds = np.zeros(len(test))\nfor model in models_lgbm:\n    LGBM_preds += model.predict(test) / len(models_lgbm)\ntest['LGBM_MAE'] = LGBM_preds\n\n\n\nlgb_params = {\n    'objective': 'MSE',\n    'n_estimators': 1000,\n    'random_state': 1,\n}\n\noof_predictions_lgbm, models_lgbm = get_MAE_oof(X, y, lgb_params, model_type='LGBM')\n\nX['LGBM_MSE_diff'] = oof_predictions_lgbm - X['LGBM_MAE']\n\n\nLGBM_preds = np.zeros(len(test))\nfor model in models_lgbm:\n    LGBM_preds += model.predict(test) / len(models_lgbm)\ntest['LGBM_MSE_diff'] = LGBM_preds - test['LGBM_MAE']\n\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-29T21:32:01.436182Z","iopub.execute_input":"2024-09-29T21:32:01.436691Z","iopub.status.idle":"2024-09-29T21:33:51.875955Z","shell.execute_reply.started":"2024-09-29T21:32:01.436636Z","shell.execute_reply":"2024-09-29T21:33:51.874740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Let's use Autogluon to fit the \"improved\" dataset.\n\nOf course time here can be tweaked, as well as using or not GPU.","metadata":{}},{"cell_type":"code","source":"cat_cols","metadata":{"execution":{"iopub.status.busy":"2024-09-29T21:33:51.877859Z","iopub.execute_input":"2024-09-29T21:33:51.878479Z","iopub.status.idle":"2024-09-29T21:33:51.886529Z","shell.execute_reply.started":"2024-09-29T21:33:51.878424Z","shell.execute_reply":"2024-09-29T21:33:51.885305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from autogluon.tabular import TabularPredictor\n\n# Assume 'X' is your input DataFrame and 'y' is the target (price)\nX['price'] = y\n\n# Fit the predictor\npredictor = TabularPredictor(label='price',\n                             eval_metric='rmse',\n                             problem_type='regression').fit(\n    X,\n    presets='best_quality',\n    time_limit=3600*1,\n    verbosity=2,\n    num_gpus=0,\n    included_model_types=['GBM', 'CAT', 'XGB'],  # Boosting models\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-29T21:33:51.888063Z","iopub.execute_input":"2024-09-29T21:33:51.888454Z","iopub.status.idle":"2024-09-29T22:34:25.196059Z","shell.execute_reply.started":"2024-09-29T21:33:51.888417Z","shell.execute_reply":"2024-09-29T22:34:25.194515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = predictor.predict(test)\npd.DataFrame(y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-09-29T23:14:28.486683Z","iopub.execute_input":"2024-09-29T23:14:28.487211Z","iopub.status.idle":"2024-09-29T23:14:50.673809Z","shell.execute_reply.started":"2024-09-29T23:14:28.487164Z","shell.execute_reply":"2024-09-29T23:14:50.672556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A bit of blending with the solution already blended from kagglers. Can be tweaked (currently 50/50).\n# sub_blend = pd.read_csv('https://www.kaggle.com/code/jayshrivastava/blendin')\noptuna = pd.read_csv(\"/kaggle/input/71936-80214/submission (7).csv\")\nsample_sub = pd.read_csv('/kaggle/input/playground-series-s4e9/sample_submission.csv')\nsample_sub['price'] =  y_pred * 0.55 + optuna['price'] * 0.45\nsample_sub.to_csv(\"submission.csv\", index=False)\nsample_sub.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-29T23:20:39.676099Z","iopub.execute_input":"2024-09-29T23:20:39.676686Z","iopub.status.idle":"2024-09-29T23:20:40.058607Z","shell.execute_reply.started":"2024-09-29T23:20:39.676641Z","shell.execute_reply":"2024-09-29T23:20:40.057380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id\tprice\n0\t188533\t18924.729623\n1\t188534\t78680.620925\n2\t188535\t58480.317674\n3\t188536\t30165.350990\n4\t188537\t31191.151196\n","metadata":{},"execution_count":null,"outputs":[]}]}