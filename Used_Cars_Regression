{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":76728,"databundleVersionId":9057646,"sourceType":"competition"}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-14T07:19:16.043889Z","iopub.execute_input":"2024-09-14T07:19:16.044386Z","iopub.status.idle":"2024-09-14T07:19:16.053680Z","shell.execute_reply.started":"2024-09-14T07:19:16.044350Z","shell.execute_reply":"2024-09-14T07:19:16.052646Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s4e9/sample_submission.csv\n/kaggle/input/playground-series-s4e9/train.csv\n/kaggle/input/playground-series-s4e9/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport re\nimport polars as pl\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.inspection import permutation_importance\nimport shap\nimport warnings\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.svm import SVR\nimport xgboost as xgb\nimport lightgbm as lgb\n# Ignore all warnings\nwarnings.filterwarnings('ignore')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T07:19:16.253986Z","iopub.execute_input":"2024-09-14T07:19:16.254315Z","iopub.status.idle":"2024-09-14T07:19:24.922045Z","shell.execute_reply.started":"2024-09-14T07:19:16.254282Z","shell.execute_reply":"2024-09-14T07:19:24.921259Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"%%writefile data_preprocessing.py\n\nimport os\nimport re\nimport polars as pl\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold\nimport numpy as np\nimport warnings\n\n# Ignore all warnings\nwarnings.filterwarnings('ignore')\n\nclass DataPreprocessor:\n    def __init__(self, train_file, test_file=None, rare_threshold=40, additional_categorical=None):\n        \"\"\"\n        Initialize the DataPreprocessor.\n\n        Parameters:\n        - train_file (str): Path to the training CSV file.\n        - test_file (str, optional): Path to the testing CSV file.\n        - rare_threshold (int): Threshold below which categories are considered rare.\n        - additional_categorical (list, optional): List of additional categorical column names.\n        \"\"\"\n        self.train_file = train_file\n        self.test_file = test_file\n        self.train = None\n        self.test = None\n        self.label_encoders = {}\n        self.scaler = StandardScaler()\n        self.rare_threshold = rare_threshold\n        self.CAT_SIZE = []\n        self.CAT_EMB = []\n        self.RARE = []\n        self.CATS = []  # List of categorical columns to encode\n        self.NUMS = []  # List of numerical columns to scale\n        self.additional_categorical = additional_categorical if additional_categorical else []\n\n    def load_data(self):\n        self.train = pl.read_csv(self.train_file)\n        if self.test_file:\n            self.test = pl.read_csv(self.test_file)\n            print(\"Training and Testing data loaded successfully.\")\n        else:\n            print(\"Training data loaded successfully.\")\n    \n    def replace_null_values(self):\n        # Replace specific null representations with \"Unknown\"\n        for column in [\"fuel_type\", \"clean_title\", \"accident\", \"transmission\"]:\n            if column in self.train.columns:\n                unique_values = self.train.unique(subset=[column], maintain_order=True)[column]\n                pl_null = unique_values[2] if len(unique_values) > 2 else None  # Adjust index as needed\n                mapping = {'â€“': pl_null, \"not supported\": pl_null, pl_null: \"Unknown\"}\n                self.train = self.train.with_columns(pl.col(column).replace(mapping))\n                if self.test and column in self.test.columns:\n                    self.test = self.test.with_columns(pl.col(column).replace(mapping))\n                self.train = self.train.with_columns(pl.col(column).replace(pl_null, \"Unknown\"))\n                if self.test and column in self.test.columns:\n                    self.test = self.test.with_columns(pl.col(column).replace(pl_null, \"Unknown\"))\n        print(\"Null values replaced.\")\n\n    def categorize_transmission(self, trans):\n        if trans is None or pd.isnull(trans):\n            return \"Other\"\n        trans = trans.lower()\n        if \"manual\" in trans or \"m/t\" in trans:\n            return \"Manual\"\n        elif \"automatic\" in trans or \"a/t\" in trans or \"cvt\" in trans:\n            return \"Automatic\"\n        else:\n            return \"Other\"\n\n    def extract_speed(self, trans):\n        if trans is None or pd.isnull(trans):\n            return \"Other\"\n        match = re.search(r\"(\\d+)-speed\", trans, re.IGNORECASE)\n        if match:\n            return match.group(1)\n        else:\n            return \"Other\"\n\n    def categorize_transmissions(self):\n        # Apply categorization on training data\n        df_pandas = self.train.to_pandas()\n        df_pandas[\"transmission_category\"] = df_pandas[\"transmission\"].apply(self.categorize_transmission)\n        df_pandas[\"speed_category\"] = df_pandas[\"transmission\"].apply(self.extract_speed)\n        self.train = pl.from_pandas(df_pandas)\n\n        # Apply the same to testing data if available\n        if self.test:\n            df_test = self.test.to_pandas()\n            df_test[\"transmission_category\"] = df_test[\"transmission\"].apply(self.categorize_transmission)\n            df_test[\"speed_category\"] = df_test[\"transmission\"].apply(self.extract_speed)\n            self.test = pl.from_pandas(df_test)\n        print(\"Transmissions categorized.\")\n\n    def extract_engine_details(self, engine_str):\n        if pd.isnull(engine_str):\n            return 0.0, 0.0, 0\n        hp_match = re.search(r\"(\\d{2,3}\\.?\\d*)HP\", engine_str)\n        l_match = re.search(r\"(\\d\\.?\\d*)L\", engine_str)\n        cyl_match = re.search(r\"(\\d+) Cylinder\", engine_str)\n        hp = float(hp_match.group(1)) if hp_match else 0.0\n        liters = float(l_match.group(1)) if l_match else 0.0\n        cylinders = int(cyl_match.group(1)) if cyl_match else 0\n        return hp, liters, cylinders\n\n    def apply_engine_extraction(self):\n        # Apply extraction on training data\n        df_pandas = self.train.to_pandas()\n        engine_details = df_pandas['engine'].apply(self.extract_engine_details)\n        df_pandas['HP'], df_pandas['Liters'], df_pandas['Cylinders'] = zip(*engine_details)\n        self.train = pl.from_pandas(df_pandas)\n        self.train = self.train.drop([\"transmission\", \"engine\"])\n        \n        # Apply the same to testing data if available\n        if self.test:\n            df_test = self.test.to_pandas()\n            engine_details_test = df_test['engine'].apply(self.extract_engine_details)\n            df_test['HP'], df_test['Liters'], df_test['Cylinders'] = zip(*engine_details_test)\n            self.test = pl.from_pandas(df_test)\n            self.test = self.test.drop([\"transmission\", \"engine\"])\n        print(\"Engine details extracted.\")\n\n    def detect_categorical_columns(self):\n        \"\"\"\n        Automatically detect categorical columns based on data types and additional specifications.\n        \"\"\"\n        df_pandas = self.train.to_pandas()\n        # Detect categorical columns based on data types\n        categorical_columns = df_pandas.select_dtypes(include=['object', 'category', 'bool', 'string']).columns.tolist()\n        \n        # Include additional categorical columns provided by the user\n        for col in self.additional_categorical:\n            if col in df_pandas.columns and col not in categorical_columns:\n                categorical_columns.append(col)\n        \n        print(f\"Detected categorical columns: {categorical_columns}\")\n        return categorical_columns\n\n    def label_encode_and_handle_rare(self, cat_cols):\n        \"\"\"\n        Label encode categorical columns and handle rare categories.\n        Rare categories are replaced with 0.\n        \"\"\"\n        df_pandas = self.train.to_pandas()\n        if self.test:\n            df_test = self.test.to_pandas()\n        else:\n            df_test = None\n\n        for c in cat_cols:\n            print(f\"\\nProcessing categorical column: {c}\")\n            # Ensure the column is of a categorical type\n            if df_pandas[c].dtype not in ['object', 'category', 'bool', 'string', 'int64']:\n                print(f\"Skipping column {c} as it is not of a categorical type.\")\n                continue\n            # Factorize to get integer codes\n            df_pandas[c], uniques = pd.factorize(df_pandas[c], sort=True)\n            if df_test is not None:\n                # Apply the same factorization to test data\n                df_test[c] = pd.Categorical(df_test[c], categories=uniques).codes\n                df_test[c] = df_test[c].astype(int)\n            # Shift to ensure minimum label is 0\n            df_pandas[c] -= df_pandas[c].min()\n            if df_test is not None:\n                df_test[c] -= df_pandas[c].min()\n            # Get value counts\n            vc = df_pandas[c].value_counts()\n            # Identify rare categories\n            rare_categories = vc[vc < self.rare_threshold].index.values\n            self.RARE.append(rare_categories)\n            # Number of unique categories excluding rare\n            n_unique = df_pandas[c].nunique()\n            min_val = df_pandas[c].min()\n            max_val = df_pandas[c].max()\n            rare_count = len(rare_categories)\n            print(f'{c}: nunique={n_unique}, min={min_val}, max={max_val}, rare_ct={rare_count}')\n            # Update CAT_SIZE and CAT_EMB\n            # +1 for rare category\n            cat_size = max_val + 2  # Adding one more for rare\n            self.CAT_SIZE.append(cat_size)\n            self.CAT_EMB.append(int(np.ceil(np.sqrt(cat_size))))\n            # Increment labels by 1 to reserve 0 for rare\n            df_pandas[c] += 1\n            if df_test is not None:\n                df_test[c] += 1\n            # Replace rare categories with 0\n            rare_indices = rare_categories + 1  # Since labels have been incremented\n            df_pandas.loc[df_pandas[c].isin(rare_indices), c] = 0\n            if df_test is not None:\n                df_test.loc[df_test[c].isin(rare_indices), c] = 0\n            # Store LabelEncoder (if needed elsewhere)\n            le = LabelEncoder()\n            # Fit on non-rare categories\n            non_rare = df_pandas[df_pandas[c] != 0][c]\n            le.fit(non_rare)\n            self.label_encoders[c] = le\n            print(f\"Label encoding completed for column: {c}\")\n        \n        # Update the training and testing data\n        self.train = pl.from_pandas(df_pandas)\n        if self.test:\n            self.test = pl.from_pandas(df_test)\n        print(\"\\nLabel encoding and rare category handling complete.\")\n\n    def fill_nulls(self):\n        df_pandas = self.train.to_pandas()\n        numerical_cols = ['speed_category', 'HP', 'Liters', 'Cylinders']\n        for col in numerical_cols:\n            if col in df_pandas.columns:\n                df_pandas[col].fillna(0, inplace=True)\n                if self.test and col in self.test.columns:\n                    df_test = self.test.to_pandas()\n                    df_test[col].fillna(0, inplace=True)\n                    self.test = pl.from_pandas(df_test)\n        self.train = pl.from_pandas(df_pandas)\n        print(\"Null values filled.\")\n\n    def drop_columns(self, columns):\n        existing_columns_train = self.train.columns\n        columns_to_drop = [col for col in columns if col in existing_columns_train]\n        self.train = self.train.drop(columns_to_drop)\n        if self.test:\n            existing_columns_test = self.test.columns\n            columns_to_drop_test = [col for col in columns if col in existing_columns_test]\n            self.test = self.test.drop(columns_to_drop_test)\n        print(f\"Dropped columns: {columns_to_drop}\")\n\n    def detect_numerical_columns(self):\n        \"\"\"\n        Detect numerical columns that need to be scaled.\n        \"\"\"\n        df_pandas = self.train.to_pandas()\n        numerical_columns = df_pandas.select_dtypes(include=['float64', 'int64']).columns.tolist()\n        # Exclude categorical columns\n        numerical_columns = [col for col in numerical_columns if col not in self.CATS]\n        # Further exclude target variable if present\n        if 'price' in numerical_columns:\n            numerical_columns.remove('price')\n        self.NUMS = numerical_columns\n        print(f\"Detected numerical columns for scaling: {self.NUMS}\")\n        return self.NUMS\n\n    def scale_features(self):\n        df_pandas = self.train.to_pandas()\n        numerical_columns = self.NUMS\n        print(f\"Scaling numerical columns: {numerical_columns}\")\n        # Fit scaler on training data\n        df_pandas[numerical_columns] = self.scaler.fit_transform(df_pandas[numerical_columns])\n        self.train = pl.from_pandas(df_pandas)\n        \n        # Apply scaler to test data if available\n        if self.test:\n            df_test = self.test.to_pandas()\n            df_test[numerical_columns] = self.scaler.transform(df_test[numerical_columns])\n            self.test = pl.from_pandas(df_test)\n        print(\"Features scaled.\")\n\n    def preprocess(self):\n        self.load_data()\n        self.replace_null_values()\n        self.categorize_transmissions()\n        self.apply_engine_extraction()\n        # Automatically detect categorical columns\n        categorical_columns = self.detect_categorical_columns()\n        self.CATS = categorical_columns\n        self.label_encode_and_handle_rare(cat_cols=categorical_columns)\n        self.fill_nulls()\n        self.drop_columns([\"id\"])  # Ensure 'id' exists or handle if missing\n        self.detect_numerical_columns()\n        self.scale_features()\n        print(\"Preprocessing complete.\")\n\n    def get_embedding_info(self):\n        \"\"\"\n        Returns a dictionary with categorical columns as keys and a tuple of (CAT_SIZE, CAT_EMB)\n        \"\"\"\n        embedding_info = {}\n        for idx, c in enumerate(self.CATS):\n            embedding_info[c] = (self.CAT_SIZE[idx], self.CAT_EMB[idx])\n        return embedding_info\n\n    def print_dataframe(self, dataset='train'):\n        # Display the dataframe\n        if dataset == 'train':\n            return self.train\n        elif dataset == 'test' and self.test is not None:\n            return self.test\n        else:\n            print(f\"No dataset named '{dataset}' found.\")\n            return None\n\n# Example usage:\n# preprocessor = DataPreprocessor(\n#     train_file='train.csv',\n#     test_file='test.csv',\n#     rare_threshold=40,\n#     additional_categorical=['brand', 'model']  # Specify additional categorical columns here\n# )\n# preprocessor.preprocess()\n# processed_train = preprocessor.print_dataframe('train')\n# processed_test = preprocessor.print_dataframe('test')\n# embedding_info = preprocessor.get_embedding_info()\n# print(embedding_info)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T07:19:24.924192Z","iopub.execute_input":"2024-09-14T07:19:24.925070Z","iopub.status.idle":"2024-09-14T07:19:24.940092Z","shell.execute_reply.started":"2024-09-14T07:19:24.925023Z","shell.execute_reply":"2024-09-14T07:19:24.939077Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Overwriting data_preprocessing.py\n","output_type":"stream"}]},{"cell_type":"code","source":"# %%writefile plots.py\n\n\n# import os\n# import re\n# import polars as pl\n# import pandas as pd\n# import seaborn as sns\n# import matplotlib.pyplot as plt\n# from sklearn.preprocessing import LabelEncoder, StandardScaler\n# from sklearn.ensemble import RandomForestRegressor\n# from sklearn.model_selection import train_test_split\n# from sklearn.inspection import permutation_importance\n# import shap\n# import warnings\n\n# # Ignore all warnings\n# warnings.filterwarnings('ignore')\n\n\n# class Plotter:\n#     def __init__(self, X, y):\n#         \"\"\"\n#         Initializes the Plotter with preprocessed and scaled features and target data.\n        \n#         Parameters:\n#         - X: Feature DataFrame (already scaled)\n#         - y: Target Series (already scaled)\n#         \"\"\"\n#         self.X = X\n#         self.y = y\n\n\n#     def plot_correlation_matrix(self):\n#         \"\"\"\n#         Plots the correlation matrix of the combined feature and target data.\n#         \"\"\"\n#         # Combine X and y into one DataFrame\n#         df_combined = pd.concat([self.X, self.y], axis=1)\n\n#         # Calculate the correlation matrix\n#         corr_matrix = df_combined.corr()\n\n#         # Plot the correlation matrix using a heatmap\n#         plt.figure(figsize=(10, 8))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, xticklabels=corr_matrix.columns, yticklabels=corr_matrix.columns)\n#         plt.title(\"Correlation Matrix\", fontsize=16)\n#         plt.xticks(rotation=45, ha='right')  # Rotate the x-axis labels slightly for better readability\n#         plt.yticks(rotation=0)  # Keep y-axis labels horizontal\n#         plt.tight_layout()\n#         plt.show()\n        \n    \n#     def plot_feature_importance(self, model):\n#         \"\"\"\n#         Plots feature importance using the provided trained model.\n        \n#         Parameters:\n#         - model: A trained model (e.g., RandomForestRegressor) with a `feature_importances_` attribute.\n#         \"\"\"\n#         feature_importances = model.feature_importances_\n#         importance_df = pd.DataFrame({\n#             'Feature': self.X.columns,\n#             'Importance': feature_importances\n#         }).sort_values(by='Importance', ascending=False)\n\n#         # Plot Feature Importance\n#         plt.figure(figsize=(10, 6))\n#         sns.barplot(x='Importance', y='Feature', data=importance_df, palette='coolwarm')\n#         plt.title(\"Feature Importance\", fontsize=16)\n#         plt.tight_layout()\n#         plt.show()\n    \n#     def plot_permutation_importance(self, model, random_state=42, n_estimators=100, n_repeats=10):\n#         \"\"\"\n#         Plots permutation feature importance based on the preprocessed data (already scaled).\n        \n#         Parameters:\n#         - random_state: Random seed for reproducibility (default 42)\n#         - n_estimators: Number of trees in the RandomForestRegressor (default 100)\n#         - n_repeats: Number of times to shuffle the data during permutation importance (default 10)\n#         \"\"\"\n\n#         perm_importance = permutation_importance(model, self.X, self.y, n_repeats=n_repeats, random_state=random_state, scoring='neg_root_mean_squared_error')\n\n#         # Step 3: Create a DataFrame to store the results\n#         perm_importance_df = pd.DataFrame({\n#             'Feature': self.X.columns,  # Use X's original column names\n#             'Importance': perm_importance.importances_mean\n#         }).sort_values(by='Importance', ascending=False)\n\n#         # Step 4: Plot Permutation Feature Importance\n#         plt.figure(figsize=(10, 6))\n#         sns.barplot(x='Importance', y='Feature', data=perm_importance_df, palette='coolwarm')\n#         plt.title(\"Permutation Feature Importance (Scaled)\", fontsize=16)\n#         plt.tight_layout()\n#         plt.show()\n        \n        \n#     def plot_shap_summary(self, model):\n#         \"\"\"\n#         Plots a SHAP summary plot for the provided model.\n        \n#         Parameters:\n#         - model: A trained model (e.g., RandomForestRegressor)\n#         \"\"\"\n#         # Create SHAP explainer\n#         explainer = shap.TreeExplainer(model)\n\n#         # Calculate SHAP values for the feature set\n#         shap_values = explainer.shap_values(self.X)\n\n#         # Plot SHAP summary plot (global interpretation)\n#         shap.summary_plot(shap_values, self.X, feature_names=self.X.columns)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T07:19:24.941668Z","iopub.execute_input":"2024-09-14T07:19:24.942081Z","iopub.status.idle":"2024-09-14T07:19:24.951800Z","shell.execute_reply.started":"2024-09-14T07:19:24.942037Z","shell.execute_reply":"2024-09-14T07:19:24.950849Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import data_preprocessing\nimport plots\nimport importlib\nimportlib.reload(data_preprocessing)\nimportlib.reload(plots)\nfrom data_preprocessing import DataPreprocessor\nfrom plots import Plotter","metadata":{"execution":{"iopub.status.busy":"2024-09-14T07:19:24.953883Z","iopub.execute_input":"2024-09-14T07:19:24.954255Z","iopub.status.idle":"2024-09-14T07:19:24.969094Z","shell.execute_reply.started":"2024-09-14T07:19:24.954222Z","shell.execute_reply":"2024-09-14T07:19:24.968235Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"DATAPATH = \"/kaggle/input/playground-series-s4e9/\"\nTRAIN_SET = DATAPATH + \"train.csv\"\nTEST_SET = DATAPATH + \"test.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-09-14T07:19:24.969982Z","iopub.execute_input":"2024-09-14T07:19:24.970253Z","iopub.status.idle":"2024-09-14T07:19:24.974480Z","shell.execute_reply.started":"2024-09-14T07:19:24.970222Z","shell.execute_reply":"2024-09-14T07:19:24.973520Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# data = pl.read_csv(TRAIN_SET)\n# y = data[\"price\"]","metadata":{"execution":{"iopub.status.busy":"2024-09-14T07:19:24.975686Z","iopub.execute_input":"2024-09-14T07:19:24.975997Z","iopub.status.idle":"2024-09-14T07:19:24.981469Z","shell.execute_reply.started":"2024-09-14T07:19:24.975957Z","shell.execute_reply":"2024-09-14T07:19:24.980500Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# # Example usage\n# preprocessor = DataPreprocessor(TRAIN_SET)\n# preprocessor.preprocess()\n# X = preprocessor.train.drop(\"price\")","metadata":{"execution":{"iopub.status.busy":"2024-09-14T07:19:24.982730Z","iopub.execute_input":"2024-09-14T07:19:24.983441Z","iopub.status.idle":"2024-09-14T07:19:24.988531Z","shell.execute_reply.started":"2024-09-14T07:19:24.983406Z","shell.execute_reply":"2024-09-14T07:19:24.987770Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# preprocessor.print_dataframe()","metadata":{"execution":{"iopub.status.busy":"2024-09-14T07:19:24.989623Z","iopub.execute_input":"2024-09-14T07:19:24.989953Z","iopub.status.idle":"2024-09-14T07:19:24.995784Z","shell.execute_reply.started":"2024-09-14T07:19:24.989914Z","shell.execute_reply":"2024-09-14T07:19:24.995007Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import KFold\n# import tensorflow as tf\n# from tensorflow.keras.models import Model\n# from tensorflow.keras.layers import Dense, Dropout, Input, Embedding\n# from tensorflow.keras.layers import Concatenate, Multiply\n# import tensorflow.keras.backend as K\n\n# print('TF Version',tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T07:19:24.996727Z","iopub.execute_input":"2024-09-14T07:19:24.996985Z","iopub.status.idle":"2024-09-14T07:19:25.003787Z","shell.execute_reply.started":"2024-09-14T07:19:24.996957Z","shell.execute_reply":"2024-09-14T07:19:25.002962Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# EPOCHS = 3\n# LRS = [0.001]*2 + [0.0001]*1\n\n# def lrfn(epoch):\n#     return LRS[epoch]\n\n# rng = [i for i in range(EPOCHS)]\n# lr_y = [lrfn(x) for x in rng]\n# plt.figure(figsize=(10, 4))\n# plt.plot(rng, lr_y, '-o')\n# print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\". \\\n#         format(lr_y[0], max(lr_y), lr_y[-1]))\n# plt.xlabel(\"Epoch\")\n# plt.ylabel(\"Learning Rate\")\n# plt.title(\"Learning Rate Schedule\")\n# plt.show()\n\n# lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T07:19:25.006164Z","iopub.execute_input":"2024-09-14T07:19:25.006522Z","iopub.status.idle":"2024-09-14T07:19:25.012020Z","shell.execute_reply.started":"2024-09-14T07:19:25.006476Z","shell.execute_reply":"2024-09-14T07:19:25.011117Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\n# List all physical devices\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    print(f\"GPUs Available: {gpus}\")\nelse:\n    print(\"No GPUs found. Using CPU.\")\n\n    \n    \ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        # Enable memory growth for each GPU\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        logical_gpus = tf.config.list_logical_devices('GPU')\n        print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n    except RuntimeError as e:\n        # Memory growth must be set before GPUs have been initialized\n        print(e)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Input, Embedding, Flatten, Concatenate\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# GPU Configuration\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        # Enable memory growth\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        logical_gpus = tf.config.list_logical_devices('GPU')\n        print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n    except RuntimeError as e:\n        print(e)\nelse:\n    print(\"No GPUs found. Using CPU.\")\n\n# Import the DataPreprocessor class\nfrom data_preprocessing import DataPreprocessor\n\n# Define your version number for OOF predictions\nVER = 1\n\n# Initialize Preprocessor\npreprocessor = DataPreprocessor(\n    train_file=TRAIN_SET,  # Replace with your actual training file path\n    # test_file='test.csv',    # Replace with your actual testing file path\n    rare_threshold=40,\n    additional_categorical=['brand', 'model']  # Specify additional categorical columns here\n)\npreprocessor.preprocess()\n\n# Retrieve processed data\nprocessed_train = preprocessor.print_dataframe('train').to_pandas()\n# processed_test = preprocessor.print_dataframe('test').to_pandas()\nembedding_info = preprocessor.get_embedding_info()\nprint(\"Embedding Info:\", embedding_info)\n\n# Define categorical and numerical columns\nCATS = preprocessor.CATS\nNUMS = preprocessor.NUMS\n\n# Define target\nTARGET = 'price'\n\n# Split the data into training and validation sets (80:20)\nX = processed_train.drop(columns=[TARGET])\ny = processed_train[TARGET].values\n\nX_train_cats, X_valid_cats, X_train_nums, X_valid_nums, y_train, y_valid = train_test_split(\n    X[CATS].values,\n    X[NUMS].values,\n    y,\n    test_size=0.2,\n    random_state=42\n)\n\n# Learning Rate Schedule\nEPOCHS = 15\nLRS = [0.001] * 2 + [0.0001] * 1\n\ndef lrfn(epoch):\n    return LRS[epoch] if epoch < len(LRS) else LRS[-1]\n\n# Plot Learning Rate Schedule\nrng = list(range(EPOCHS))\nlr_y = [lrfn(x) for x in rng]\nplt.figure(figsize=(10, 4))\nplt.plot(rng, lr_y, '-o')\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(lr_y[0], max(lr_y), lr_y[-1]))\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Learning Rate\")\nplt.title(\"Learning Rate Schedule\")\nplt.show()\n\nlr_callback = LearningRateScheduler(lrfn, verbose=True)\n\n# Build Keras Model\ndef build_model(embedding_info, numerical_input_size):\n    # CATEGORICAL FEATURES\n    x_input_cats = Input(shape=(len(CATS),), name='categorical_input')\n    embs = []\n    for j, cat in enumerate(CATS):\n        num_categories, embed_dim = embedding_info[cat]\n        e = Embedding(input_dim=num_categories, output_dim=embed_dim, name=f'embedding_{cat}')\n        x = e(x_input_cats[:, j])\n        x = Flatten()(x)\n        embs.append(x)\n    \n    # NUMERICAL FEATURES\n    x_input_nums = Input(shape=(numerical_input_size,), name='numerical_input')\n    \n    # COMBINE\n    x = Concatenate(axis=-1)(embs + [x_input_nums]) \n    x = Dense(256, activation='relu')(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dense(256, activation='relu')(x)\n    output = Dense(1, activation='linear')(x)\n    \n    model = Model(inputs=[x_input_cats, x_input_nums], outputs=output)\n    \n    return model\n\n# Initialize Model\nmodel = build_model(embedding_info, numerical_input_size=len(NUMS))\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=lrfn(0)), \n    loss=\"mean_squared_error\", \n    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n)\n\n# Display Model Summary\nmodel.summary()\n\n# Train the Model\nhistory = model.fit(\n    [X_train_cats, X_train_nums], y_train, \n    validation_data=([X_valid_cats, X_valid_nums], y_valid),\n    callbacks=[lr_callback],\n    batch_size=64, epochs=EPOCHS, verbose=2\n)\n\n# Plot Training and Validation RMSE\nplt.figure(figsize=(10, 6))\nplt.plot(history.history['root_mean_squared_error'], label='Train RMSE')\nplt.plot(history.history['val_root_mean_squared_error'], label='Validation RMSE')\nplt.xlabel('Epoch')\nplt.ylabel('RMSE')\nplt.title('Training and Validation RMSE')\nplt.legend()\nplt.show()\n\n# Predict on Validation Set\noof_preds = model.predict([X_valid_cats, X_valid_nums], batch_size=512).flatten()\n\n# Compute RMSE for Validation Set\nrmse = np.sqrt(np.mean((oof_preds - y_valid) ** 2))\nprint('Validation RMSE =', rmse)\n\n# Compute Overall CV RMSE (Here it's just the validation RMSE since we're not using K-Fold)\nrsme = rmse\nprint(\"Overall CV RMSE =\", rsme)\n\n# Save OOF Predictions\nif 'id' in processed_train.columns:\n    # Ensure that the indices match correctly\n    oof_df = processed_train.iloc[X_valid_cats[:,0].astype(int)].loc[:, ['id']].copy()\n    oof_df[\"pred\"] = oof_preds\n    oof_df.to_csv(f\"oof_v{VER}.csv\", index=False)\nelse:\n    oof_df = pd.DataFrame({'pred': oof_preds})\n    oof_df.to_csv(f\"oof_v{VER}.csv\", index=False)\n    print(\"Warning: 'id' column not found. OOF predictions saved without 'id'.\")\n\n# Predict on Test Set (Uncomment if using test data)\n# X_test_cats = processed_test[CATS].values\n# X_test_nums = processed_test[NUMS].values\n# test_preds = model.predict([X_test_cats, X_test_nums], batch_size=512).flatten()\n\n# Save Test Predictions (Uncomment if using test data)\n# processed_test['preds'] = test_preds\n# processed_test.to_csv('test_with_preds.csv', index=False)\n# print(\"Test predictions saved to 'test_with_preds.csv'\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-14T07:19:25.013045Z","iopub.execute_input":"2024-09-14T07:19:25.013441Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Training data loaded successfully.\nNull values replaced.\nTransmissions categorized.\nEngine details extracted.\nDetected categorical columns: ['brand', 'model', 'fuel_type', 'ext_col', 'int_col', 'accident', 'clean_title', 'transmission_category', 'speed_category']\n\nProcessing categorical column: brand\nbrand: nunique=57, min=0, max=56, rare_ct=8\nLabel encoding completed for column: brand\n\nProcessing categorical column: model\nmodel: nunique=1897, min=0, max=1896, rare_ct=909\nLabel encoding completed for column: model\n\nProcessing categorical column: fuel_type\nfuel_type: nunique=6, min=0, max=5, rare_ct=0\nLabel encoding completed for column: fuel_type\n\nProcessing categorical column: ext_col\next_col: nunique=319, min=0, max=318, rare_ct=176\nLabel encoding completed for column: ext_col\n\nProcessing categorical column: int_col\nint_col: nunique=156, min=0, max=155, rare_ct=86\nLabel encoding completed for column: int_col\n\nProcessing categorical column: accident\naccident: nunique=3, min=0, max=2, rare_ct=0\nLabel encoding completed for column: accident\n\nProcessing categorical column: clean_title\nclean_title: nunique=2, min=0, max=1, rare_ct=0\nLabel encoding completed for column: clean_title\n\nProcessing categorical column: transmission_category\ntransmission_category: nunique=3, min=0, max=2, rare_ct=0\nLabel encoding completed for column: transmission_category\n\nProcessing categorical column: speed_category\nspeed_category: nunique=10, min=0, max=9, rare_ct=0\nLabel encoding completed for column: speed_category\n\nLabel encoding and rare category handling complete.\nNull values filled.\nDropped columns: ['id']\nDetected numerical columns for scaling: ['model_year', 'milage', 'HP', 'Liters', 'Cylinders']\nScaling numerical columns: ['model_year', 'milage', 'HP', 'Liters', 'Cylinders']\nFeatures scaled.\nPreprocessing complete.\nEmbedding Info: {'brand': (58, 8), 'model': (1898, 44), 'fuel_type': (7, 3), 'ext_col': (320, 18), 'int_col': (157, 13), 'accident': (4, 2), 'clean_title': (3, 2), 'transmission_category': (4, 2), 'speed_category': (11, 4)}\nLearning rate schedule: 0.001 to 0.001 to 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x400 with 1 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ categorical_input   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\nâ”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ get_item (\u001b[38;5;33mGetItem\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ categorical_inpuâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ get_item_1          â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ categorical_inpuâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mGetItem\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ get_item_2          â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ categorical_inpuâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mGetItem\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ get_item_3          â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ categorical_inpuâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mGetItem\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ get_item_4          â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ categorical_inpuâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mGetItem\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ get_item_5          â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ categorical_inpuâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mGetItem\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ get_item_6          â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ categorical_inpuâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mGetItem\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ get_item_7          â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ categorical_inpuâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mGetItem\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ get_item_8          â”‚ (\u001b[38;5;45mNone\u001b[0m)            â”‚          \u001b[38;5;34m0\u001b[0m â”‚ categorical_inpuâ€¦ â”‚\nâ”‚ (\u001b[38;5;33mGetItem\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ embedding_brand     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         â”‚        \u001b[38;5;34m464\u001b[0m â”‚ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\nâ”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ embedding_model     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)        â”‚     \u001b[38;5;34m83,512\u001b[0m â”‚ get_item_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\nâ”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ embedding_fuel_type â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         â”‚         \u001b[38;5;34m21\u001b[0m â”‚ get_item_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\nâ”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ embedding_ext_col   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚      \u001b[38;5;34m5,760\u001b[0m â”‚ get_item_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\nâ”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ embedding_int_col   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)        â”‚      \u001b[38;5;34m2,041\u001b[0m â”‚ get_item_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\nâ”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ embedding_accident  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         â”‚          \u001b[38;5;34m8\u001b[0m â”‚ get_item_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\nâ”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ embedding_clean_tiâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         â”‚          \u001b[38;5;34m6\u001b[0m â”‚ get_item_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\nâ”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ embedding_transmisâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         â”‚          \u001b[38;5;34m8\u001b[0m â”‚ get_item_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\nâ”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ embedding_speed_caâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         â”‚         \u001b[38;5;34m44\u001b[0m â”‚ get_item_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\nâ”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ embedding_brand[\u001b[38;5;34mâ€¦\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ embedding_model[\u001b[38;5;34mâ€¦\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ embedding_fuel_tâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ embedding_ext_coâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ embedding_int_coâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ embedding_accideâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ embedding_clean_â€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ embedding_transmâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ embedding_speed_â€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ numerical_input     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\nâ”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ concatenate         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    â”‚\nâ”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ flatten_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ flatten_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ flatten_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ flatten_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ flatten_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ numerical_input[\u001b[38;5;34mâ€¦\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚     \u001b[38;5;34m26,112\u001b[0m â”‚ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚     \u001b[38;5;34m65,792\u001b[0m â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚     \u001b[38;5;34m65,792\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚        \u001b[38;5;34m257\u001b[0m â”‚ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ categorical_input   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ categorical_inpuâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ get_item_1          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ categorical_inpuâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ get_item_2          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ categorical_inpuâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ get_item_3          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ categorical_inpuâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ get_item_4          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ categorical_inpuâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ get_item_5          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ categorical_inpuâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ get_item_6          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ categorical_inpuâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ get_item_7          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ categorical_inpuâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ get_item_8          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ categorical_inpuâ€¦ â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ embedding_brand     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">464</span> â”‚ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ embedding_model     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,512</span> â”‚ get_item_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ embedding_fuel_type â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> â”‚ get_item_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ embedding_ext_col   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,760</span> â”‚ get_item_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ embedding_int_col   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,041</span> â”‚ get_item_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ embedding_accident  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> â”‚ get_item_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ embedding_clean_tiâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> â”‚ get_item_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ embedding_transmisâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> â”‚ get_item_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ embedding_speed_caâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span> â”‚ get_item_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ embedding_brand[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ embedding_model[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ embedding_fuel_tâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ embedding_ext_coâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ embedding_int_coâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ embedding_accideâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ embedding_clean_â€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ embedding_transmâ€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ embedding_speed_â€¦ â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ numerical_input     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ concatenate         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ flatten_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ flatten_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ flatten_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ flatten_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ flatten_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\nâ”‚                     â”‚                   â”‚            â”‚ numerical_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">26,112</span> â”‚ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> â”‚ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m249,817\u001b[0m (975.85 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">249,817</span> (975.85 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m249,817\u001b[0m (975.85 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">249,817</span> (975.85 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\nEpoch 1: LearningRateScheduler setting learning rate to 0.001.\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1726298385.526134     128 service.cc:145] XLA service 0x7d1b60009d70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1726298385.526186     128 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1726298385.526190     128 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1726298387.709299     128 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"2357/2357 - 13s - 5ms/step - loss: 5671077888.0000 - root_mean_squared_error: 75306.5547 - val_loss: 4660953600.0000 - val_root_mean_squared_error: 68271.1719 - learning_rate: 0.0010\n\nEpoch 2: LearningRateScheduler setting learning rate to 0.001.\nEpoch 2/100\n2357/2357 - 5s - 2ms/step - loss: 5476904960.0000 - root_mean_squared_error: 74006.1094 - val_loss: 4638344192.0000 - val_root_mean_squared_error: 68105.3906 - learning_rate: 0.0010\n\nEpoch 3: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 3/100\n2357/2357 - 5s - 2ms/step - loss: 5424754688.0000 - root_mean_squared_error: 73652.9375 - val_loss: 4632942592.0000 - val_root_mean_squared_error: 68065.7188 - learning_rate: 1.0000e-04\n\nEpoch 4: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 4/100\n2357/2357 - 5s - 2ms/step - loss: 5418058752.0000 - root_mean_squared_error: 73607.4609 - val_loss: 4629873664.0000 - val_root_mean_squared_error: 68043.1719 - learning_rate: 1.0000e-04\n\nEpoch 5: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 5/100\n2357/2357 - 5s - 2ms/step - loss: 5413425152.0000 - root_mean_squared_error: 73575.9844 - val_loss: 4627152384.0000 - val_root_mean_squared_error: 68023.1797 - learning_rate: 1.0000e-04\n\nEpoch 6: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 6/100\n2357/2357 - 5s - 2ms/step - loss: 5409331712.0000 - root_mean_squared_error: 73548.1562 - val_loss: 4631084032.0000 - val_root_mean_squared_error: 68052.0703 - learning_rate: 1.0000e-04\n\nEpoch 7: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 7/100\n2357/2357 - 6s - 2ms/step - loss: 5406173184.0000 - root_mean_squared_error: 73526.6797 - val_loss: 4625669120.0000 - val_root_mean_squared_error: 68012.2734 - learning_rate: 1.0000e-04\n\nEpoch 8: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 8/100\n2357/2357 - 5s - 2ms/step - loss: 5402971648.0000 - root_mean_squared_error: 73504.9062 - val_loss: 4624700416.0000 - val_root_mean_squared_error: 68005.1484 - learning_rate: 1.0000e-04\n\nEpoch 9: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 9/100\n2357/2357 - 5s - 2ms/step - loss: 5398949376.0000 - root_mean_squared_error: 73477.5391 - val_loss: 4621421056.0000 - val_root_mean_squared_error: 67981.0312 - learning_rate: 1.0000e-04\n\nEpoch 10: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 10/100\n2357/2357 - 5s - 2ms/step - loss: 5396197376.0000 - root_mean_squared_error: 73458.8125 - val_loss: 4622505472.0000 - val_root_mean_squared_error: 67989.0078 - learning_rate: 1.0000e-04\n\nEpoch 11: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 11/100\n2357/2357 - 5s - 2ms/step - loss: 5393401344.0000 - root_mean_squared_error: 73439.7812 - val_loss: 4623961088.0000 - val_root_mean_squared_error: 67999.7109 - learning_rate: 1.0000e-04\n\nEpoch 12: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 12/100\n2357/2357 - 6s - 2ms/step - loss: 5390324736.0000 - root_mean_squared_error: 73418.8281 - val_loss: 4619939328.0000 - val_root_mean_squared_error: 67970.1328 - learning_rate: 1.0000e-04\n\nEpoch 13: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 13/100\n2357/2357 - 5s - 2ms/step - loss: 5387106816.0000 - root_mean_squared_error: 73396.9141 - val_loss: 4623786496.0000 - val_root_mean_squared_error: 67998.4297 - learning_rate: 1.0000e-04\n\nEpoch 14: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 14/100\n2357/2357 - 5s - 2ms/step - loss: 5384410624.0000 - root_mean_squared_error: 73378.5391 - val_loss: 4619214848.0000 - val_root_mean_squared_error: 67964.8047 - learning_rate: 1.0000e-04\n\nEpoch 15: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 15/100\n2357/2357 - 5s - 2ms/step - loss: 5380847104.0000 - root_mean_squared_error: 73354.2578 - val_loss: 4618834944.0000 - val_root_mean_squared_error: 67962.0078 - learning_rate: 1.0000e-04\n\nEpoch 16: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 16/100\n2357/2357 - 5s - 2ms/step - loss: 5378454528.0000 - root_mean_squared_error: 73337.9453 - val_loss: 4620121600.0000 - val_root_mean_squared_error: 67971.4766 - learning_rate: 1.0000e-04\n\nEpoch 17: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 17/100\n2357/2357 - 5s - 2ms/step - loss: 5376122368.0000 - root_mean_squared_error: 73322.0391 - val_loss: 4618596352.0000 - val_root_mean_squared_error: 67960.2578 - learning_rate: 1.0000e-04\n\nEpoch 18: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 18/100\n2357/2357 - 5s - 2ms/step - loss: 5372897280.0000 - root_mean_squared_error: 73300.0469 - val_loss: 4617863680.0000 - val_root_mean_squared_error: 67954.8672 - learning_rate: 1.0000e-04\n\nEpoch 19: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 19/100\n2357/2357 - 5s - 2ms/step - loss: 5370375680.0000 - root_mean_squared_error: 73282.8438 - val_loss: 4618865152.0000 - val_root_mean_squared_error: 67962.2344 - learning_rate: 1.0000e-04\n\nEpoch 20: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 20/100\n2357/2357 - 5s - 2ms/step - loss: 5367049728.0000 - root_mean_squared_error: 73260.1484 - val_loss: 4619216384.0000 - val_root_mean_squared_error: 67964.8203 - learning_rate: 1.0000e-04\n\nEpoch 21: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 21/100\n2357/2357 - 5s - 2ms/step - loss: 5364265984.0000 - root_mean_squared_error: 73241.1484 - val_loss: 4617936896.0000 - val_root_mean_squared_error: 67955.4062 - learning_rate: 1.0000e-04\n\nEpoch 22: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 22/100\n2357/2357 - 5s - 2ms/step - loss: 5360939008.0000 - root_mean_squared_error: 73218.4375 - val_loss: 4617589760.0000 - val_root_mean_squared_error: 67952.8516 - learning_rate: 1.0000e-04\n\nEpoch 23: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 23/100\n2357/2357 - 5s - 2ms/step - loss: 5358454272.0000 - root_mean_squared_error: 73201.4609 - val_loss: 4621870080.0000 - val_root_mean_squared_error: 67984.3359 - learning_rate: 1.0000e-04\n\nEpoch 24: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 24/100\n2357/2357 - 5s - 2ms/step - loss: 5356518400.0000 - root_mean_squared_error: 73188.2422 - val_loss: 4621124096.0000 - val_root_mean_squared_error: 67978.8516 - learning_rate: 1.0000e-04\n\nEpoch 25: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 25/100\n2357/2357 - 6s - 2ms/step - loss: 5353308160.0000 - root_mean_squared_error: 73166.3047 - val_loss: 4629922304.0000 - val_root_mean_squared_error: 68043.5312 - learning_rate: 1.0000e-04\n\nEpoch 26: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 26/100\n2357/2357 - 5s - 2ms/step - loss: 5351016960.0000 - root_mean_squared_error: 73150.6484 - val_loss: 4623416832.0000 - val_root_mean_squared_error: 67995.7109 - learning_rate: 1.0000e-04\n\nEpoch 27: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 27/100\n2357/2357 - 5s - 2ms/step - loss: 5348080128.0000 - root_mean_squared_error: 73130.5703 - val_loss: 4620101632.0000 - val_root_mean_squared_error: 67971.3281 - learning_rate: 1.0000e-04\n\nEpoch 28: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 28/100\n2357/2357 - 5s - 2ms/step - loss: 5345606656.0000 - root_mean_squared_error: 73113.6562 - val_loss: 4630675456.0000 - val_root_mean_squared_error: 68049.0625 - learning_rate: 1.0000e-04\n\nEpoch 29: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 29/100\n2357/2357 - 5s - 2ms/step - loss: 5342652928.0000 - root_mean_squared_error: 73093.4531 - val_loss: 4623045120.0000 - val_root_mean_squared_error: 67992.9766 - learning_rate: 1.0000e-04\n\nEpoch 30: LearningRateScheduler setting learning rate to 0.0001.\nEpoch 30/100\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-09-14T05:29:52.219929Z","iopub.execute_input":"2024-09-14T05:29:52.220613Z","iopub.status.idle":"2024-09-14T05:29:52.259430Z","shell.execute_reply.started":"2024-09-14T05:29:52.220549Z","shell.execute_reply":"2024-09-14T05:29:52.258002Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# # Dictionary for RandomForestRegressor parameters\n# rf_params = {\n#     'n_estimators': 100,\n#     'criterion': 'squared_error',\n#     'max_depth': None,\n#     'min_samples_split': 2,\n#     'min_samples_leaf': 1,\n#     'min_weight_fraction_leaf': 0.0,\n#     'max_features': 'auto',\n#     'max_leaf_nodes': None,\n#     'bootstrap': True,\n#     'oob_score': False,\n#     'n_jobs': -1,\n#     'random_state': 42,\n#     'verbose': 0,\n#     'warm_start': False,\n#     'ccp_alpha': 0.0,\n#     'max_samples': None\n# }\n\n\n\n# # Dictionary for SVR parameters\n# svr_params = {\n#     'kernel': 'rbf',\n#     'degree': 3,\n#     'gamma': 'scale',\n#     'coef0': 0.0,\n#     'tol': 1e-3,\n#     'C': 1.0,\n#     'epsilon': 0.1,\n#     'shrinking': True,\n#     'cache_size': 200,\n#     'verbose': False,\n#     'max_iter': -1\n# }\n\n\n# xgb_model = xgb.XGBRegressor(\n#     objective='reg:squarederror',\n#     n_estimators=100,\n#     max_depth=6,\n#     learning_rate=0.1,\n#     subsample=0.8,\n#     colsample_bytree=0.8,\n#     random_state=42,\n#     tree_method='gpu_hist'  # Enable GPU\n# )\n\n# lgb_model = lgb.LGBMRegressor(\n#     boosting_type='gbdt',\n#     num_leaves=31,\n#     learning_rate=0.1,\n#     n_estimators=100,\n#     random_state=42,\n#     device='gpu'  # Enable GPU\n# )\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-13T06:57:51.196198Z","iopub.execute_input":"2024-09-13T06:57:51.196621Z","iopub.status.idle":"2024-09-13T06:57:51.205568Z","shell.execute_reply.started":"2024-09-13T06:57:51.196587Z","shell.execute_reply":"2024-09-13T06:57:51.204447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_dict = {}","metadata":{"execution":{"iopub.status.busy":"2024-09-13T06:57:51.206859Z","iopub.execute_input":"2024-09-13T06:57:51.207570Z","iopub.status.idle":"2024-09-13T06:57:51.216870Z","shell.execute_reply.started":"2024-09-13T06:57:51.207536Z","shell.execute_reply":"2024-09-13T06:57:51.215946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Instantiate the RandomForestRegressor model using the parameters from the dictionary\n# rf_model = RandomForestRegressor(**rf_params)\n# rf_model.fit(X_train, y_train)\n# rf_predictions = rf_model.predict(X_test)\n# rf_mse = np.sqrt(mean_squared_error(y_test, rf_predictions))\n# models_dict[rf_mse] = rf_model\n# print(f\"RandomForest RMSE: {rf_mse}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-13T06:57:51.217973Z","iopub.execute_input":"2024-09-13T06:57:51.218324Z","iopub.status.idle":"2024-09-13T06:58:21.797582Z","shell.execute_reply.started":"2024-09-13T06:57:51.218290Z","shell.execute_reply":"2024-09-13T06:58:21.796604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Instantiate the SVR model using the parameters from the dictionary\n# svr_model = SVR(**svr_params)\n# svr_model.fit(X_train, y_train)\n# svr_predictions = svr_model.predict(X_test)\n# svr_mse = np.sqrt(mean_squared_error(y_test, svr_predictions))\n# models_dict[svr_mse] = svr_model\n# print(f\"SVR RMSE: {svr_mse}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-13T06:58:21.798855Z","iopub.execute_input":"2024-09-13T06:58:21.799198Z","iopub.status.idle":"2024-09-13T06:58:21.803389Z","shell.execute_reply.started":"2024-09-13T06:58:21.799162Z","shell.execute_reply":"2024-09-13T06:58:21.802450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xgb_model.fit(X_train, y_train)\n# xgb_predictions = xgb_model.predict(X_test)\n# xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_predictions))\n# models_dict[xgb_rmse] = xgb_model  # Store the RMSE and model\n# print(f\"XGBoost RMSE: {xgb_rmse}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-13T06:58:21.804703Z","iopub.execute_input":"2024-09-13T06:58:21.805289Z","iopub.status.idle":"2024-09-13T06:58:22.713765Z","shell.execute_reply.started":"2024-09-13T06:58:21.805244Z","shell.execute_reply":"2024-09-13T06:58:22.712740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lgb_model.fit(X_train, y_train)\n# lgb_predictions = lgb_model.predict(X_test)\n# lgb_rmse = np.sqrt(mean_squared_error(y_test, lgb_predictions))\n# models_dict[lgb_rmse] = lgb_model  # Store the RMSE and model\n# print(f\"LightGBM RMSE: {lgb_rmse}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-13T06:58:22.715133Z","iopub.execute_input":"2024-09-13T06:58:22.715642Z","iopub.status.idle":"2024-09-13T06:58:29.305288Z","shell.execute_reply.started":"2024-09-13T06:58:22.715595Z","shell.execute_reply":"2024-09-13T06:58:29.304191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessor = DataPreprocessor(TEST_SET)\npreprocessor.preprocess()\nprint(\"Test Data Preproccessing complete\")\ntest_data = preprocessor.test","metadata":{"execution":{"iopub.status.busy":"2024-09-13T06:58:29.306927Z","iopub.execute_input":"2024-09-13T06:58:29.307382Z","iopub.status.idle":"2024-09-13T06:58:32.004927Z","shell.execute_reply.started":"2024-09-13T06:58:29.307342Z","shell.execute_reply":"2024-09-13T06:58:32.004006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_submission(test_set, models_dict, TEST_SET = DATAPATH + \"test.csv\", output_file=\"submission.csv\"):\n    \n    \n    best_rmse = min(models_dict.keys())  # Get the smallest RMSE\n    model = models_dict[best_rmse]  # Get the corresponding model\n    print(f\"Best RMSE: {best_rmse}\")\n    # Assuming test_set is a polars DataFrame\n    # If it's not, we can convert it from pandas to polars\n    if isinstance(test_set, pd.DataFrame):\n        test_set = pl.DataFrame(test_set)\n    \n    # Extract the 'id' column\n    ids = pl.read_csv(TEST_SET)[\"id\"]\n\n    # Predict on the entire test set (assuming model.predict() works on a whole dataframe)\n    predictions = model.predict(test_set.to_pandas())  # converting polars DataFrame to pandas for prediction\n\n    # Create a new polars DataFrame with 'id' and 'price' (predictions)\n    submission = pl.DataFrame({\n        'id': ids,\n        'price': predictions\n    })\n\n    # Write to CSV\n    submission.write_csv(output_file)\n    print(f\"Submission file saved as {output_file}\")\n\n\ncreate_submission(test_data, models_dict)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T06:58:32.006150Z","iopub.execute_input":"2024-09-13T06:58:32.006470Z","iopub.status.idle":"2024-09-13T06:58:32.445430Z","shell.execute_reply.started":"2024-09-13T06:58:32.006438Z","shell.execute_reply":"2024-09-13T06:58:32.444373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotter = Plotter(X, y)\n# plotter.plot_feature_importance(model)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T06:58:32.446692Z","iopub.execute_input":"2024-09-13T06:58:32.447035Z","iopub.status.idle":"2024-09-13T06:58:32.451357Z","shell.execute_reply.started":"2024-09-13T06:58:32.446982Z","shell.execute_reply":"2024-09-13T06:58:32.450263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### imports","metadata":{}},{"cell_type":"code","source":"# import data_preprocessing\n# import plots\n# import importlib\n# importlib.reload(data_preprocessing)\n# importlib.reload(plots)","metadata":{"execution":{"iopub.status.busy":"2024-09-13T06:58:32.452574Z","iopub.execute_input":"2024-09-13T06:58:32.452884Z","iopub.status.idle":"2024-09-13T06:58:32.461457Z","shell.execute_reply.started":"2024-09-13T06:58:32.452846Z","shell.execute_reply":"2024-09-13T06:58:32.460372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%writefile data_preprocessing.py\n\n# import os\n# import re\n# import polars as pl\n# import pandas as pd\n# import seaborn as sns\n# import matplotlib.pyplot as plt\n# from sklearn.preprocessing import LabelEncoder, StandardScaler\n# from sklearn.ensemble import RandomForestRegressor\n# from sklearn.model_selection import train_test_split\n# from sklearn.inspection import permutation_importance\n# import shap\n# import warnings\n\n# # Ignore all warnings\n# warnings.filterwarnings('ignore')\n\n\n# class DataPreprocessor:\n#     def __init__(self, train_file, test_file=None):\n#         self.train_file = train_file\n#         self.test_file = test_file\n#         self.data = None\n#         self.label_encoders = {}\n#         self.scaler = StandardScaler()\n\n#     def load_data(self):\n#         self.data = pl.read_csv(self.train_file)\n#         print(\"Data loaded successfully.\")\n    \n#     def replace_null_values(self):\n#         types = self.data.unique(subset=[\"fuel_type\"], maintain_order=True)[\"fuel_type\"]\n#         pl_null = types[2]\n#         mapping = {'â€“': pl_null, \"not supported\": pl_null, pl_null: \"Unknown\"}\n#         self.data = self.data.with_columns(fuel_type=pl.col(\"fuel_type\").replace(mapping))\n#         self.data = self.data.with_columns(clean_title=pl.col(\"clean_title\").replace(mapping))\n#         self.data = self.data.with_columns(accident=pl.col(\"accident\").replace(mapping))\n#         self.data = self.data.with_columns(transmission=pl.col(\"transmission\").replace(mapping))\n#         self.data = self.data.with_columns(fuel_type=pl.col(\"fuel_type\").replace(pl_null, \"Unknown\"))\n#         print(\"Null values replaced.\")\n    \n#     def categorize_transmission(self, trans):\n#         if trans is None:\n#             return None\n#         trans = trans.lower()\n#         if \"manual\" in trans or \"m/t\" in trans:\n#             return \"Manual\"\n#         elif \"automatic\" in trans or \"a/t\" in trans or \"cvt\" in trans:\n#             return \"Automatic\"\n#         else:\n#             return \"Other\"\n    \n#     def extract_speed(self, trans):\n#         if trans is None:\n#             return \"Other\"\n#         match = re.search(r\"(\\d+)-speed\", trans, re.IGNORECASE)\n#         if match:\n#             return match.group(1)\n#         else:\n#             return \"Other\"\n    \n#     def categorize_transmissions(self):\n#         df_pandas = self.data.to_pandas()\n#         df_pandas[\"transmission_category\"] = df_pandas[\"transmission\"].apply(self.categorize_transmission)\n#         df_pandas[\"speed_category\"] = df_pandas[\"transmission\"].apply(self.extract_speed)\n#         self.data = pl.from_pandas(df_pandas)\n#         print(\"Transmissions categorized.\")\n    \n#     def extract_engine_details(self, engine_str):\n#         if pd.isnull(engine_str):\n#             return None, None, None\n#         hp_match = re.search(r\"(\\d{2,3}\\.?\\d*)HP\", engine_str)\n#         l_match = re.search(r\"(\\d\\.?\\d*)L\", engine_str)\n#         cyl_match = re.search(r\"(\\d+) Cylinder\", engine_str)\n#         hp = hp_match.group(1) if hp_match else None\n#         liters = l_match.group(1) if l_match else None\n#         cylinders = cyl_match.group(1) if cyl_match else None\n#         return hp, liters, cylinders\n\n#     def apply_engine_extraction(self):\n#         df_pandas = self.data.to_pandas()\n#         df_pandas['HP'], df_pandas['Liters'], df_pandas['Cylinders'] = zip(*df_pandas['engine'].apply(self.extract_engine_details))\n#         self.data = pl.from_pandas(df_pandas)\n#         self.data = self.data.drop(\"transmission\")\n#         self.data = self.data.drop(\"engine\")\n#         print(\"Engine details extracted.\")\n\n#     def label_encode(self):\n#         cat_data = self.data.select([col for col in self.data.columns if not self.data[col].dtype.is_numeric()])\n#         cat_data = cat_data.to_pandas()\n#         for column in cat_data.select_dtypes(include=['object']).columns:\n#             self.label_encoders[column] = LabelEncoder()\n#             cat_data[column] = self.label_encoders[column].fit_transform(cat_data[column])\n#         num_data = self.data.select([col for col in self.data.columns if self.data[col].dtype.is_numeric()])\n#         self.data = pl.from_pandas(pd.concat([num_data.to_pandas(), cat_data], axis=1))\n#         print(\"Categorical columns label encoded.\")\n\n#     def fill_nulls(self):\n#         df_pandas = self.data.to_pandas()\n#         df_pandas['speed_category'].fillna(0, inplace=True)\n#         df_pandas['HP'].fillna(0, inplace=True)\n#         df_pandas['Liters'].fillna(0, inplace=True)\n#         df_pandas['Cylinders'].fillna(0, inplace=True)\n#         self.data = pl.from_pandas(df_pandas)\n#         print(\"Null values filled.\")\n    \n#     def drop_columns(self, columns):\n#         self.data = self.data.drop(columns)\n#         print(f\"Dropped columns: {columns}\")\n\n#     def scale_features(self):\n#         df_pandas = self.data.to_pandas()\n#         numeric_columns = df_pandas.select_dtypes(include=['float64', 'int64']).columns\n#         df_pandas[numeric_columns] = self.scaler.fit_transform(df_pandas[numeric_columns])\n#         self.data = pl.from_pandas(df_pandas)\n#         print(\"Features scaled.\")\n    \n#     def plot_feature_importance(self, target_column):\n#         X = self.data.drop(target_column).to_pandas()\n#         y = self.data[target_column].to_pandas()\n#         model = RandomForestRegressor(n_estimators=100, random_state=42)\n#         model.fit(X, y)\n#         feature_importances = model.feature_importances_\n#         importance_df = pd.DataFrame({\n#             'Feature': X.columns,\n#             'Importance': feature_importances\n#         }).sort_values(by='Importance', ascending=False)\n#         plt.figure(figsize=(10, 6))\n#         sns.barplot(x='Importance', y='Feature', data=importance_df, palette='coolwarm')\n#         plt.title(f\"Feature Importance with respect to '{target_column}'\")\n#         plt.tight_layout()\n#         plt.show()\n\n#     def preprocess(self):\n#         self.load_data()\n#         self.replace_null_values()\n#         self.categorize_transmissions()\n#         self.apply_engine_extraction()\n#         self.label_encode()\n#         self.fill_nulls()\n#         self.drop_columns([\"id\"])\n#         self.scale_features()\n#         print(\"Preprocessing complete.\")\n    \n#     def print_dataframe(self):\n#         # Display the dataframe\n#         return self.data","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-13T06:58:32.462787Z","iopub.execute_input":"2024-09-13T06:58:32.463110Z","iopub.status.idle":"2024-09-13T06:58:32.475405Z","shell.execute_reply.started":"2024-09-13T06:58:32.463078Z","shell.execute_reply":"2024-09-13T06:58:32.474557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%writefile plots.py\n\n\n# import os\n# import re\n# import polars as pl\n# import pandas as pd\n# import seaborn as sns\n# import matplotlib.pyplot as plt\n# from sklearn.preprocessing import LabelEncoder, StandardScaler\n# from sklearn.ensemble import RandomForestRegressor\n# from sklearn.model_selection import train_test_split\n# from sklearn.inspection import permutation_importance\n# import shap\n# import warnings\n\n# # Ignore all warnings\n# warnings.filterwarnings('ignore')\n\n\n# class Plotter:\n#     def __init__(self, X, y):\n#         \"\"\"\n#         Initializes the Plotter with preprocessed and scaled features and target data.\n        \n#         Parameters:\n#         - X: Feature DataFrame (already scaled)\n#         - y: Target Series (already scaled)\n#         \"\"\"\n#         self.X = X\n#         self.y = y\n\n\n#     def plot_correlation_matrix(self):\n#         \"\"\"\n#         Plots the correlation matrix of the combined feature and target data.\n#         \"\"\"\n#         # Combine X and y into one DataFrame\n#         df_combined = pd.concat([self.X, self.y], axis=1)\n\n#         # Calculate the correlation matrix\n#         corr_matrix = df_combined.corr()\n\n#         # Plot the correlation matrix using a heatmap\n#         plt.figure(figsize=(10, 8))\n#         sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, xticklabels=corr_matrix.columns, yticklabels=corr_matrix.columns)\n#         plt.title(\"Correlation Matrix\", fontsize=16)\n#         plt.xticks(rotation=45, ha='right')  # Rotate the x-axis labels slightly for better readability\n#         plt.yticks(rotation=0)  # Keep y-axis labels horizontal\n#         plt.tight_layout()\n#         plt.show()\n        \n    \n#     def plot_feature_importance(self, model):\n#         \"\"\"\n#         Plots feature importance using the provided trained model.\n        \n#         Parameters:\n#         - model: A trained model (e.g., RandomForestRegressor) with a `feature_importances_` attribute.\n#         \"\"\"\n#         feature_importances = model.feature_importances_\n#         importance_df = pd.DataFrame({\n#             'Feature': self.X.columns,\n#             'Importance': feature_importances\n#         }).sort_values(by='Importance', ascending=False)\n\n#         # Plot Feature Importance\n#         plt.figure(figsize=(10, 6))\n#         sns.barplot(x='Importance', y='Feature', data=importance_df, palette='coolwarm')\n#         plt.title(\"Feature Importance\", fontsize=16)\n#         plt.tight_layout()\n#         plt.show()\n    \n#     def plot_permutation_importance(self, model, random_state=42, n_estimators=100, n_repeats=10):\n#         \"\"\"\n#         Plots permutation feature importance based on the preprocessed data (already scaled).\n        \n#         Parameters:\n#         - random_state: Random seed for reproducibility (default 42)\n#         - n_estimators: Number of trees in the RandomForestRegressor (default 100)\n#         - n_repeats: Number of times to shuffle the data during permutation importance (default 10)\n#         \"\"\"\n\n#         perm_importance = permutation_importance(model, self.X, self.y, n_repeats=n_repeats, random_state=random_state, scoring='neg_root_mean_squared_error')\n\n#         # Step 3: Create a DataFrame to store the results\n#         perm_importance_df = pd.DataFrame({\n#             'Feature': self.X.columns,  # Use X's original column names\n#             'Importance': perm_importance.importances_mean\n#         }).sort_values(by='Importance', ascending=False)\n\n#         # Step 4: Plot Permutation Feature Importance\n#         plt.figure(figsize=(10, 6))\n#         sns.barplot(x='Importance', y='Feature', data=perm_importance_df, palette='coolwarm')\n#         plt.title(\"Permutation Feature Importance (Scaled)\", fontsize=16)\n#         plt.tight_layout()\n#         plt.show()\n        \n        \n#     def plot_shap_summary(self, model):\n#         \"\"\"\n#         Plots a SHAP summary plot for the provided model.\n        \n#         Parameters:\n#         - model: A trained model (e.g., RandomForestRegressor)\n#         \"\"\"\n#         # Create SHAP explainer\n#         explainer = shap.TreeExplainer(model)\n\n#         # Calculate SHAP values for the feature set\n#         shap_values = explainer.shap_values(self.X)\n\n#         # Plot SHAP summary plot (global interpretation)\n#         shap.summary_plot(shap_values, self.X, feature_names=self.X.columns)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-13T06:58:32.478510Z","iopub.execute_input":"2024-09-13T06:58:32.478824Z","iopub.status.idle":"2024-09-13T06:58:32.492142Z","shell.execute_reply.started":"2024-09-13T06:58:32.478791Z","shell.execute_reply":"2024-09-13T06:58:32.491296Z"},"trusted":true},"execution_count":null,"outputs":[]}]}